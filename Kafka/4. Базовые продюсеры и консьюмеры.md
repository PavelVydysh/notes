# Kafka

## Базовые продюсеры и консьюмеры

- Данные в kafka хранятся в виде массива байт

### Настройки продюсера

Клиент не производит отправку данных сразу, после инициализации отправки. Он дожидается либо передельного размера пакета, 
либо ожидает определенное время.  

- `batch.size` - определяет максимальный размер пакета в байтах, который продюсер может отправить в брокер.
Если сообщение весит больше `batch.size`, то оно не будет упаковано и будет отправлено отдельно. 
Как только, по мере сбора сообщений, пакет вес пакета доберется до этой отметки, он будет отправлен.
В случае отправки сообщений с ключами, пакеты будут формироваться отдельно для каждого ключа, тк каждый батч уходит в свою партицию.

- `max.request.bytes` - определяет максимальный размер запроса в байтах, который продюсер может отправить в брокер.
За один запрос может улетать несколько пакетов, соответственно важно ограничивать максимальный размер одного запроса,
чтобы не перегружать сеть и брокера. Если набор пакетов по весу будет превышать `max.request.bytes`, то пакеты будут 
разделены на несколько запросов.

- `linger.ms` - время в мс, после которого продюсер отправляет данные. При этом, если `batch.size` наберется быстрее,
то данные будут отправлены сразу после достижения `batch.size`.

- `acks` - количество реплик, которые должны подтвердить получение сообщения, прежде чем оно будет считаться доставленным.
  - `all` - от всех in-sync реплик(смотрится по min.insync.replicas, но только если не все реплики доступны)
  - `1` - от лидера
  - 0 - не ждать подтверждение получения сообщения

- `retries` - устанавливает, сколько раз продюсер будет пытаться повторно отправить сообщение после неудачи.

- `retry.backoff.ms` - устанавливает задержку в миллисекундах между повторными попытками отправки сообщения, в случае
неуспешной отправки.

- `max.in.flight.requests.per.connection` - устанавливает, сколько запросов может быть отправлено одновременно, не дожидаясь подтверждения предыдущих.
Изначально стоит 1, означает, что пока запрос не пройдет, другие запросы не будут уходить. Не гарантирует последовательную доставку сообщений

### Настройки консьюмера

Kafka не отправляет самостоятельно сообщения, консьюмеры сами из нее читают.

- `fetch.min.bytes` - определяет минимальный набор данных, который консьюмер должен получить от бркоера в одном запросе.
Если данных недостаточно - консьюмер будет ждать пока не наберется нужный объем.

- `fetch.max.wait` - определяет максимальное время ожидания сообщений от брокера.
Например, если `fetch.min.bytes` не набран и консьюмер ожидает сообщений, то через `fetch.max.wait`, он прочитает те сообщения, которые смог получить.

- `auto-offset-reset` - позволяет изменить позицию, с которой консумер начинает читать сообщения из топика. 
Может быть полезно в различных сценариях, таких как повторная обработка данных или восстановление после сбоя.
Может случиться так, что кафка может затереть смещение консьюмера.
  - `earliest` - сбрасывает смещение на самое раннее доступное сообщение
  - `latest` - сбрасывает смещение на самое последнее сообщение

- `auto.commit.enabled` - включение/отключение автоматического подтверждения прочтения сообщений.

- `auto.commit.interval.ms` - время, через которое прочтение сообщения будет подтверждено(при включенном `auto-commit`)
Смещения коммитятся автоматически через интервал, заданный в `auto.commit.interval.ms`, независимо от того, завершена обработка сообщения или нет. 
Это может привести к ситуации, когда смещение коммитится до завершения обработки, что может вызвать потерю данных в случае ошибки.
Необходимо ставить меньше чем максимальное время работы сессии.

### Стратегии назначения партиций на консьюмере

В группе консьюмеров один консьюмер назначается лидером группы(случайным образом),
лидер определяет какой консьюмер какие партиции читает

Стратегии назначения партиций:

- Range - разделы распределяются по диапазонам, каждый консумер получает последовательные разделы.\
Для каждого топика количество партиций делится на количество консьюмеров.\
Например, есть 10 разделов и 3 консьюмера: первый поулчит разделы 0-3, второй 4-6, третий 7-9.\
Эта стратегия используется по умолчанию.

- RoundRobin - разделы распределяются по кругу, каждый консумер получает разделы равномерно, независимо от порядка.
Например, есть 2 топика с 6 и 3 разделами и 3 консьюмера, получится следующее распределение:
  - Топик 1:
    - Консьюмер 1: 0, 3
    - Консьюмер 2: 1, 4
    - Консьюмер 3: 2, 5
  - Топик 2:
    - Консьюмер 1: 0
    - Консьюмер 2: 1
    - Консьюмер 3: 2

### Key for partition

Сообщения с одинаковыми ключами попадают в одну и ту же партицию,
это необходимо для последовательного чтения сообщений, относящихся к одной логической единице.\
Например, транзакции пользователя важно читать последовательно, поэтому идентфиикатор пользователя может быть ключом сообщений.

### Ошибки при доставке сообщений

Возможна ситуация, когда продюсер не может писать в Kafka, либо она недоступна.\
Как можно обработать такие ситуации:
- Перестать посылать сообщения, например когда очередь сообщений очень важна и нельзя допустить
чтобы другие продюсеры условно могли использовать "несуществующие" данные
- Dead letter queue, все сообщения, которые не удалось доставить - сохраняем и позже сможем их переотправить/проанализировать
- Retry паттерн, если основной топик не доступен - кладем в retry хранилище, если и оно недоступно - в dead letter queue.
При таком подходе порядок не будет сохраняться.

### Паттерн надежной доставки сообщений(Outbox worker)

Основное приложение пишет данные для отправки в бд, создается отдельный сервис, отправляющий данные в кафку из этой бд.\
Он в моменте собирает пачку сообщений и отправляет их в кафку.\
Если сообщения удалось доставить в Kafka, то они помечаются, как доставленные, либо удаляются из бд.\
Если сообщения не удалось отправить, то он помечает сообщения как неотправленные и через время пытается снова отправить.